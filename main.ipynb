{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0854b29-5fb0-487f-8d3c-f2d825a90445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load dataset\n",
    "csv_file = \"C://Users//LIKIANU//Downloads//large_multilingual_translation_dataset.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Available translation models\n",
    "language_pairs = {\n",
    "    \"English to French\": \"Helsinki-NLP/opus-mt-en-fr\",\n",
    "    \"English to Spanish\": \"Helsinki-NLP/opus-mt-en-es\",\n",
    "    \"English to German\": \"Helsinki-NLP/opus-mt-en-de\",\n",
    "    \"French to English\": \"Helsinki-NLP/opus-mt-fr-en\",\n",
    "    \"Spanish to English\": \"Helsinki-NLP/opus-mt-es-en\",\n",
    "    \"German to English\": \"Helsinki-NLP/opus-mt-de-en\"\n",
    "}\n",
    "\n",
    "# Streamlit App Interface\n",
    "st.title(\"Real-Time Language Translation (NMT)\")\n",
    "st.write(\"Bridging Language Barriers with Neural Machine Translation\")\n",
    "\n",
    "# User Input\n",
    "selected_pair = st.selectbox(\"Select Language Pair\", list(language_pairs.keys()))\n",
    "user_text = st.text_area(\"Enter text to translate:\")\n",
    "\n",
    "if st.button(\"Translate\") and user_text:\n",
    "    source_lang, target_lang = selected_pair.split(\" to \")\n",
    "    \n",
    "    # Check dataset for translation\n",
    "    if source_lang in df.columns and target_lang in df.columns:\n",
    "        match = df[df[source_lang].str.lower() == user_text.lower()]\n",
    "        if not match.empty:\n",
    "            translated_text = match[target_lang].values[0]\n",
    "            st.subheader(\"Translated Text (From Dataset):\")\n",
    "            st.success(translated_text)\n",
    "        else:\n",
    "            st.write(\"Translation not found in dataset. Using NMT model...\")\n",
    "            use_model = True\n",
    "    else:\n",
    "        use_model = True\n",
    "\n",
    "    # Use model if dataset lookup fails\n",
    "    if 'use_model' in locals() and use_model:\n",
    "        model_name = language_pairs[selected_pair]\n",
    "        tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "        model = MarianMTModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Tokenize and Translate\n",
    "        inputs = tokenizer([user_text], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        translated = model.generate(**inputs)\n",
    "        translated_text = tokenizer.batch_decode(translated, skip_special_tokens=True)[0]\n",
    "        \n",
    "        # Display Output\n",
    "        st.subheader(\"Translated Text (Using Model):\")\n",
    "        st.success(translated_text)\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.write(\"Developed with ❤️ using Hugging Face Transformers, Streamlit & Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae74740-ea28-43d8-bd2f-76b3ef0dacc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from sacrebleu.metrics import TER\n",
    "import numpy as np\n",
    "\n",
    "# Define languages and respective models\n",
    "languages = {\n",
    "    \"French\": \"Helsinki-NLP/opus-mt-en-fr\",\n",
    "    \"Spanish\": \"Helsinki-NLP/opus-mt-en-es\",\n",
    "    \"German\": \"Helsinki-NLP/opus-mt-en-de\",\n",
    "    \"Hindi\": \"Helsinki-NLP/opus-mt-en-hi\",\n",
    "    \"Chinese\": \"Helsinki-NLP/opus-mt-en-zh\"\n",
    "}\n",
    "\n",
    "# Input text to translate\n",
    "text = [\"Hello, how are you?\"]\n",
    "\n",
    "# Store results\n",
    "translations = {}\n",
    "\n",
    "# Translate to multiple languages\n",
    "for lang, model_name in languages.items():\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated = model.generate(**inputs)\n",
    "    translated_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    translations[lang] = translated_text[0]\n",
    "\n",
    "# Output translations\n",
    "for lang, translated_text in translations.items():\n",
    "    print(f\"{lang}: {translated_text}\")\n",
    "\n",
    "# Example reference and candidate for evaluation\n",
    "reference = [['this', 'is', 'a', 'test']]\n",
    "candidate = ['this', 'is', 'test']\n",
    "\n",
    "# BLEU Score\n",
    "bleu_score = sentence_bleu(reference, candidate)\n",
    "print(\"BLEU Score:\", bleu_score)\n",
    "\n",
    "# METEOR Score\n",
    "meteor_score_value = meteor_score(reference, candidate)\n",
    "print(\"METEOR Score:\", meteor_score_value)\n",
    "\n",
    "# TER Score Calculation\n",
    "ter = TER()\n",
    "reference_text = [\"this is a test\"]\n",
    "candidate_text = \"this is test\"\n",
    "ter_score = ter.corpus_score([candidate_text], [[ref] for ref in reference_text])\n",
    "print(\"TER Score:\", ter_score.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae3204a-d699-4d72-a8ed-adf20055fb51",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated triple-quoted string literal (detected at line 68) (2980368134.py, line 49)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 49\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated triple-quoted string literal (detected at line 68)\n"
     ]
    }
   ],
   "source": [
    "# Translation and Evaluation using MarianMT (Helsinki-NLP)\n",
    "This notebook translates English text into multiple languages using the Helsinki-NLP MarianMT model and evaluates translations using BLEU, METEOR, and TER scores.\n",
    "\"\"\"\n",
    "\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from sacrebleu.metrics import TER\n",
    "import numpy as np\n",
    "\n",
    "# Define languages and respective models\n",
    "languages = {\n",
    "    \"French\": \"Helsinki-NLP/opus-mt-en-fr\",\n",
    "    \"Spanish\": \"Helsinki-NLP/opus-mt-en-es\",\n",
    "    \"German\": \"Helsinki-NLP/opus-mt-en-de\",\n",
    "    \"Hindi\": \"Helsinki-NLP/opus-mt-en-hi\",\n",
    "    \"Chinese\": \"Helsinki-NLP/opus-mt-en-zh\"\n",
    "}\n",
    "\n",
    "# Input text to translate\n",
    "text = [\"Hello, how are you?\"]\n",
    "\n",
    "# Store results\n",
    "translations = {}\n",
    "\n",
    "# Translate to multiple languages\n",
    "for lang, model_name in languages.items():\n",
    "    print(f\"Loading model for {lang}...\")\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated = model.generate(**inputs)\n",
    "    translated_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    translations[lang] = translated_text[0]\n",
    "    print(f\"{lang}: {translated_text[0]}\")\n",
    "\n",
    "# Display translations\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(list(translations.items()), columns=[\"Language\", \"Translation\"])\n",
    "display(df)\n",
    "\n",
    "\"\"\"\n",
    "# Translation Evaluation\n",
    "Now, we evaluate the translations using BLEU, METEOR, and TER scores.\n",
    "\"\"\"\n",
    "\n",
    "# Example reference and candidate for evaluation\n",
    "reference = [['this', 'is', 'a', 'test']]\n",
    "candidate = ['this', 'is', 'test']\n",
    "\n",
    "# BLEU Score\n",
    "bleu_score = sentence_bleu(reference, candidate)\n",
    "print(\"BLEU Score:\", bleu_score)\n",
    "\n",
    "# METEOR Score\n",
    "meteor_score_value = meteor_score(reference, candidate)\n",
    "print(\"METEOR Score:\", meteor_score_value)\n",
    "\n",
    "# TER Score Calculation\n",
    "ter = TER()\n",
    "reference_text = [\"this is a test\"]\n",
    "candidate_text = \"this is test\"\n",
    "ter_score = ter.corpus_score([candidate_text], [[ref] for ref in reference_text])\n",
    "print(\"TER Score:\", ter_score.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71a18e87-96ce-470d-b3e1-68e677d6da64",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (17978542.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    jupyter nbextension enable --py widgetsnbextension\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a14edc-415d-4f91-a647-6540dd9548a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
